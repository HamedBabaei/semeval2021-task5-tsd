{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "temprory-notebook.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbRXlKNxaIy8",
        "outputId": "9e9e9586-6816-400f-a144-38b840a78d8b"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFCpv7qfedsz"
      },
      "source": [
        "# Loadings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "Wy5H9Zsw9T3s",
        "outputId": "57183413-b002-41eb-db24-a405f90ee48a"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import cross_validator as cross_validator\n",
        "import datahandler as datahandler\n",
        "from datamodel import DataModel\n",
        "import outputmaker as outputmaker\n",
        "import metrics as metrics\n",
        "\n",
        "trial = datahandler.load_train('tsd_trial.csv', verbose=True)\n",
        "train = datahandler.load_train('tsd_train.csv', verbose=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spans</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
              "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
              "      <td>How about we stop protecting idiots and let na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
              "      <td>If people  were  smart, they would  Boycott th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      spans                                               text\n",
              "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]  Because he's a moron and a bigot. It's not any...\n",
              "1                  [29, 30, 31, 32, 33, 34]  How about we stop protecting idiots and let na...\n",
              "2            [166, 167, 168, 169, 170, 171]  If people  were  smart, they would  Boycott th..."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spans</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
              "      <td>Another violent and aggressive immigrant killi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
              "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 1, 2, 3]</td>\n",
              "      <td>Damn, a whole family. Sad indeed.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               spans                                               text\n",
              "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...  Another violent and aggressive immigrant killi...\n",
              "1                       [33, 34, 35, 36, 37, 38, 39]  I am 56 years old, I am not your fucking junio...\n",
              "2                                       [0, 1, 2, 3]                  Damn, a whole family. Sad indeed."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDwaPqrjaGlI"
      },
      "source": [
        "datamodel = DataModel(model='crf', remove_stop_words=False)\n",
        "\n",
        "output_maker = outputmaker.crf_output\n",
        "\n",
        "evaluator = metrics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjS9C0hty-_-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnHKk2luajgM",
        "outputId": "9ae82ed2-a4ba-4d1e-b485-7ff9dcdd8c8b"
      },
      "source": [
        "X_train, y_train, train_taboo_words, train_texts = cross_validator.load_data(train, [i for i in range(train.shape[0])],\n",
        "                                                                             datamodel, logger=True)\n",
        "\n",
        "X_test, y_test, test_taboo_words, test_texts = cross_validator.load_data(trial, [i for i in range(trial.shape[0])], \n",
        "                                                                   datamodel, logger=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7939/7939 [03:47<00:00, 34.83it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [00:19<00:00, 36.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za_8Xry41TmU"
      },
      "source": [
        "# PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSPC0uBU1WPk"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "from tqdm import tqdm \n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "special_chars = ['O', '4', 'Íž', 'Ã¼', 'ðŸ˜ž', 'Â»', 'â€', '\\x7f', '\"', '7', '*', '8', ')',\n",
        "      'ðŸ˜‚', 'ðŸ’€', '{', '0', 'Ê»', 'ðŸ’¨', 'â€¢', '#', '_', 'ðŸ˜Š', 'ðŸ˜œ', 'Ã³', 'ðŸ˜…', \n",
        "      'Â¬', 'â˜ ', 'ðŸ™„', 'ðŸ˜‰', 'ðŸ˜†', 'â€•','(', '.', '?', 'ðŸ˜µ', 'ðŸ’¥', ':', 'ðŸ†˜',\n",
        "      '$', '=', '+', ';', 'ðŸ”¥', 'ðŸ˜','`', 'Ã¯', '2', 'Ãª', 'Ã©', '3', '-', 'ðŸ¤¥',\n",
        "      'âš½', 'Ã‰', 'ï¸', '!', '5', 'âœ­', '9', 'ðŸ˜ˆ', 'Ëˆ', 'ðŸ˜¬', '@', 'Â«', '/', 'â–€', 'â€™',\n",
        "      'ðŸ˜¡', '1', '%', ',', '&', '6', '\\\\', ']', \"'\", '[', '^', '}', 'âš¾', '\\u200b']\n",
        "\n",
        "F_cleaner = lambda x: ''.join([w for w in x if w not in special_chars ])\n",
        "\n",
        "     \n",
        "def cleaning(X):\n",
        "    cleaned_x = []\n",
        "    for words in tqdm(X):\n",
        "        cleaned_words = []\n",
        "        for word in words :\n",
        "            w, pos, tag = word\n",
        "            cleaned_w = F_cleaner(w)\n",
        "            if len(cleaned_w) != 0:\n",
        "                cleaned_words.append( (stemmer.stem(cleaned_w), pos, tag) )\n",
        "        cleaned_x.append(cleaned_words)\n",
        "    return cleaned_x\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXyAccCThP60",
        "outputId": "76afaf8f-c51a-4cf2-b3e4-84208698a5b2"
      },
      "source": [
        "X_train = cleaning(X_train)\n",
        "X_test = cleaning(X_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7939/7939 [00:07<00:00, 1017.98it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [00:00<00:00, 1164.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztm0QCoLhPoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cf7f06-a659-4962-e8b7-4b3aec047b52"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('anoth', 'DT', 'normal'),\n",
              " ('violent', 'JJ', 'toxic'),\n",
              " ('and', 'CC', 'toxic'),\n",
              " ('aggress', 'JJ', 'toxic'),\n",
              " ('immigr', 'NN', 'toxic'),\n",
              " ('kill', 'VBG', 'normal'),\n",
              " ('a', 'DT', 'normal'),\n",
              " ('innoc', 'JJ', 'normal'),\n",
              " ('and', 'CC', 'normal'),\n",
              " ('intellig', 'JJ', 'normal'),\n",
              " ('US', 'NNP', 'normal'),\n",
              " ('citizen', 'NNP', 'normal'),\n",
              " ('sarcasm', 'NNP', 'normal')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjKnG8H8XQlL"
      },
      "source": [
        "# Prepare for modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oryxkLfJX5pZ",
        "outputId": "ce4c3a95-06a1-4d1e-a9a2-ca223131a9b2"
      },
      "source": [
        "words = set([w for x in X_train + X_test for w, tag, label in x])\n",
        "chars = set([char for x in X_train + X_test for w, tag, label in x for char in w])\n",
        "tags = set([tag for x in X_train for w, pos, tag in x])\n",
        "\n",
        "n_tags = len(tags)\n",
        "n_chars = len(chars)\n",
        "n_words = len(words)\n",
        "n_tags = len(tags)\n",
        "n_chars = len(chars)\n",
        "n_words = len(words)\n",
        "\n",
        "n_tags, n_chars, n_words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 51, 13715)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru8iDgt416bB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ivzH61OX6jL",
        "outputId": "f62569d5-1908-41ca-e65c-b0bdc654c57b"
      },
      "source": [
        "print(chars)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'w', 'v', 'u', 'S', 'p', 'x', 'C', 'T', 'H', 'G', 'Q', 'V', 'X', 'k', 't', 'i', 'N', 'M', 'f', 'L', 'e', 'y', 'R', 'U', 'Y', 'D', 'K', 'g', 'o', 'J', 'z', 'm', 'b', 'A', 'P', 'a', 's', 'd', 'n', 'B', 'h', 'E', 'c', 'q', 'I', 'j', 'F', 'Z', 'l', 'r', 'W'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtxIx3rGYfFb",
        "outputId": "1d82583b-3a55-4533-fed5-6693b2aa0e46"
      },
      "source": [
        "max([len(x) for x in X_train+X_test]), max([len(w) for x in X_train+X_test for w, tag, label in x])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(191, 149)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QQSST-DYzD-"
      },
      "source": [
        "max_len = 191\n",
        "max_len_char = 149"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljNuGcA7Y4yg"
      },
      "source": [
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1\n",
        "word2idx[\"PAD\"] = 0\n",
        "\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
        "tag2idx[\"PAD\"] = 0\n",
        "idx2tag = {i: w for w, i in tag2idx.items()}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YShg8WvZkP2",
        "outputId": "2220c28b-538f-4092-dc97-8431600e3fa5"
      },
      "source": [
        "print(word2idx[\"fuck\"])\n",
        "print(tag2idx[\"normal\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10090\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nUYPcG-ZlVe"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_word = [[word2idx[w[0]] for w in s] for s in X_train]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXfZRAR6ZmZl"
      },
      "source": [
        "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPI_Ui1WZoKi"
      },
      "source": [
        "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char2idx[\"UNK\"] = 1\n",
        "char2idx[\"PAD\"] = 0"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWpOmYbtZqNs"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_char = []\n",
        "for sentence in X_train:\n",
        "    sent_seq = []\n",
        "    for i in range(max_len):\n",
        "        word_seq = []\n",
        "        for j in range(max_len_char):\n",
        "            try:\n",
        "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
        "            except:\n",
        "                word_seq.append(char2idx.get(\"PAD\"))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_char.append(np.array(sent_seq))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atph22a70kHr",
        "outputId": "69b9e540-278c-4463-a37f-9aa4ce5aa68e"
      },
      "source": [
        "X_char[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37, 40, 30, ...,  0,  0,  0],\n",
              "       [ 3, 17, 30, ...,  0,  0,  0],\n",
              "       [37, 40, 39, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulRv1YgLZrJx",
        "outputId": "b404c00a-4c38-49c9-fbc8-5ee61ece4242"
      },
      "source": [
        "y = [[tag2idx[w[2]] for w in s] for s in X_train]\n",
        "\n",
        "len(y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2hGHQpXZsHf"
      },
      "source": [
        "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbfDMu1nZuZj"
      },
      "source": [
        "# Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ffWTV5kZt1F"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_word_tr, y_tr = X_word, y\n",
        "X_char_tr = X_char\n",
        "\n",
        "#X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word, y, test_size=0.1, random_state=2018)\n",
        "#X_char_tr, X_char_te, _, _ = train_test_split(X_char, y, test_size=0.1, random_state=2018)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuUYEW8g0e3L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn_ipDCs0MbT"
      },
      "source": [
        "#X_word_te.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3hVbKwD0MOi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz5WLPeIZyEE"
      },
      "source": [
        "# word-char based Bi-LSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD521cVRZzqJ"
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
        "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0AEEy_dZ7Au"
      },
      "source": [
        "# input and embedding for words\n",
        "word_in = Input(shape=(max_len,))\n",
        "emb_word = Embedding(input_dim=n_words + 2, output_dim=50,\n",
        "                     input_length=max_len, mask_zero=True)(word_in)\n",
        "\n",
        "# input and embeddings for characters\n",
        "char_in = Input(shape=(max_len, max_len_char,))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=20,\n",
        "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
        "# character LSTM to get word encodings by characters\n",
        "char_enc = TimeDistributed(LSTM(units=50, return_sequences=False,\n",
        "                                recurrent_dropout=0.5))(emb_char)\n",
        "\n",
        "# main LSTM\n",
        "x = concatenate([emb_word, char_enc])\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,\n",
        "                               recurrent_dropout=0.4))(x)\n",
        "out = TimeDistributed(Dense(n_tags + 1, activation=\"sigmoid\"))(main_lstm)\n",
        "\n",
        "model = Model([word_in, char_in], out)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWx_kwGlaBRH"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9tBEuSNaBnT",
        "outputId": "7261445a-db7b-4f80-dc7d-1ac38dab15bf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 191, 149)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 191)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 191, 149, 20) 1060        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 191, 50)      685850      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 191, 50)      14200       time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 191, 100)     0           embedding_2[0][0]                \n",
            "                                                                 time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 191, 100)     0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 191, 100)     60400       spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 191, 3)       303         bidirectional_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 761,813\n",
            "Trainable params: 761,813\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41QtvPljaRWq",
        "outputId": "aa41ee7c-ac60-4739-ffa2-9e8fdf6efabd"
      },
      "source": [
        "history = model.fit([X_word_tr,\n",
        "                    np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
        "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
        "                    batch_size=32, epochs=10, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 64/224 [=======>......................] - ETA: 11:32 - loss: 0.0918 - acc: 0.8997"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttgJGtBeaVQe"
      },
      "source": [
        "import pandas as pd \n",
        "hist = pd.DataFrame(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS6KqHzlaZJp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.plot(hist[\"acc\"])\n",
        "plt.plot(hist[\"val_acc\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dg7uRfvaa18",
        "outputId": "3be89b82-878d-4ed8-ed17-7cda0316f48d"
      },
      "source": [
        "y_pred = model.predict([X_word_te,\n",
        "                        np.array(X_char_te).reshape((len(X_char_te),\n",
        "                                                     max_len, max_len_char))])\n",
        "y_pred[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.1361879e-04, 9.6667194e-01, 1.9100308e-04], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9vAkKco9pWT",
        "outputId": "5841fbca-f6d8-4f26-ad57-5a1adb9cf072"
      },
      "source": [
        "np.array(X_char_te).reshape((len(X_char_te),max_len, max_len_char)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(794, 157, 198)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lueENptXydG-"
      },
      "source": [
        "#y_pred.shape[0]794\n",
        "y_prediction = []\n",
        "y_truth = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y2Mt3qxaeGz",
        "outputId": "d9c118df-5378-45a6-c320-ce05a5d88899"
      },
      "source": [
        "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(30 * \"=\")\n",
        "\n",
        "for i in range(y_pred.shape[0]):\n",
        "    #i = 314\n",
        "    p = np.argmax(y_pred[i], axis=-1)\n",
        "    \n",
        "    for w, t, pred in zip(X_word_te[i], y_te[i], p):\n",
        "        if w != 0:\n",
        "            y_prediction.append(idx2tag[pred])\n",
        "            y_truth.append(idx2tag[t])\n",
        "            #if idx2tag[t] == 'toxic' or idx2tag[pred] == 'toxic':\n",
        "            #    print(\"{} {:15}: {:5} {}\".format(i, idx2word[w], idx2tag[t], idx2tag[pred]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           ||True ||Pred\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvmndQUKvF4d"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svcf7YkNzP8l",
        "outputId": "5d46aa20-ec30-41e9-c15d-0946ae80633b"
      },
      "source": [
        "print(classification_report(y_truth, y_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.93      0.96      0.95     12786\n",
            "       toxic       0.59      0.45      0.51      1652\n",
            "\n",
            "    accuracy                           0.90     14438\n",
            "   macro avg       0.76      0.70      0.73     14438\n",
            "weighted avg       0.89      0.90      0.90     14438\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsHYNYxk1T0l"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL_a16_t1hXP",
        "outputId": "ac6ccc88-a013-4ce7-9d08-d92483d945a7"
      },
      "source": [
        "X_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('moron', 'NN', 'toxic'),\n",
              " ('bigot', 'NN', 'toxic'),\n",
              " ('complicated', 'JJ', 'normal')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upj5_MtN9ZGr",
        "outputId": "bf79224b-73a0-4774-d5c6-570ec4040aa6"
      },
      "source": [
        "X_word_te.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(794, 157)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie6QvJ2u1dVd"
      },
      "source": [
        "X_word_test = []\n",
        "no = []\n",
        "for s in X_test:\n",
        "    x_s = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            x_s.append(word2idx[w[0]])\n",
        "        except:\n",
        "            no.append(w)\n",
        "            \n",
        "    X_word_test.append(x_s)\n",
        "X_word_test = [[word2idx[w[0]] if w[0] in word2idx else word2idx[\"UNK\"] for w in s] for s in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8QcB0OrAW9j",
        "outputId": "51afe14a-e3ae-434c-8600-10b00e17652d"
      },
      "source": [
        "len(no), len(X_word_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 690)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia0Vk0pXAYqd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scmzpvqIAYmn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57LqGyTYzVnv"
      },
      "source": [
        "\n",
        "X_word_test = pad_sequences(maxlen=max_len, sequences=X_word_test, \n",
        "                            value=word2idx[\"PAD\"], padding='post', truncating='post')\n",
        "\n",
        "X_char_test = []\n",
        "for sentence in X_test:\n",
        "    sent_seq = []\n",
        "    for i in range(max_len):\n",
        "        word_seq = []\n",
        "        for j in range(max_len_char):\n",
        "            try:\n",
        "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
        "            except:\n",
        "                word_seq.append(char2idx.get(\"PAD\"))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_char_test.append(np.array(sent_seq).astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c2xUR6kNzQB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO0Ucbod1XWB"
      },
      "source": [
        "y_pred_test = model.predict([X_word_test, np.array(X_char_test).reshape((len(X_char_test),max_len, max_len_char))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSl_5lVqxbgT"
      },
      "source": [
        "y_test_preds = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgpmeEJg-VUL"
      },
      "source": [
        "for i in range(y_pred_test.shape[0]):\n",
        "\n",
        "    p = np.argmax(y_pred_test[i], axis=-1)\n",
        "    preds = []\n",
        "    for w, pred in zip(X_word_test[i], p):\n",
        "        if w != 0:\n",
        "            preds.append(idx2tag[pred])\n",
        "    y_test_preds.append(preds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfN0Fugiw8Wc",
        "outputId": "6acffb0c-83a6-4c4b-9e7b-487bb38a1a56"
      },
      "source": [
        "y_test_preds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'toxic', 'normal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-rxP6jyyCXc",
        "outputId": "c21802d3-d9a4-44f6-d7b3-fb51cd9d9f38"
      },
      "source": [
        "len(y_test_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqyAHENPyEiE",
        "outputId": "614304ad-fbfc-4fca-90b7-4f3286522cc9"
      },
      "source": [
        "predictions = output_maker(X_test, test_texts, y_test_preds)\n",
        "\n",
        "f1, p, r = evaluator.evaluate(gold = y_test, predictions = predictions)\n",
        "\n",
        "print(\"F1:{}, \\t P:{}, \\t R:{}\".format(f1, p, r))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1:0.5778733240805811, \t P:0.6616228532625453, \t R:0.603260666794722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdw1BeFeygDp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}