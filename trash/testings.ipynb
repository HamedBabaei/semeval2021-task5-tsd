{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/.local/lib/python3.6/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/.local/lib/python3.6/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import __init__\n",
    "#import models.random as random_model\n",
    "#import models.cross_validator as cross_validator\n",
    "import models.datahandler as datahandler\n",
    "from models.datamodel import DataModel\n",
    "import models.outputmaker as outputmaker\n",
    "import evaluator.metrics as metrics\n",
    "\n",
    "trial = datahandler.load_train('../data/dataset/tsd_trial.csv', verbose=True)\n",
    "train = datahandler.load_train('../data/dataset/tsd_train.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import random\n",
    "import statistics\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "def spans_to_ents(doc, spans, label):\n",
    "    \"\"\"Converts span indicies into spacy entity labels.\"\"\"\n",
    "    started = False\n",
    "    left, right, ents = 0, 0, []\n",
    "    for x in doc:\n",
    "        if x.pos_ == 'SPACE':\n",
    "            continue\n",
    "        if spans.intersection(set(range(x.idx, x.idx + len(x.text)))):\n",
    "            if not started:\n",
    "                left, started = x.idx, True\n",
    "            right = x.idx + len(x.text)\n",
    "        elif started:\n",
    "            ents.append((left, right, label))\n",
    "            started = False\n",
    "    if started:\n",
    "        ents.append((left, right, label))\n",
    "    return ents\n",
    "\n",
    "\"\"\"Automatic best effort span cleaner for SemEval 2021 Toxic Spans.\"\"\"\n",
    "\n",
    "import ast\n",
    "import csv\n",
    "import itertools\n",
    "import string\n",
    "import sys\n",
    "\n",
    "SPECIAL_CHARACTERS = string.whitespace\n",
    "\n",
    "def _contiguous_ranges(span_list):\n",
    "    \"\"\"Extracts continguous runs [1, 2, 3, 5, 6, 7] -> [(1,3), (5,7)].\"\"\"\n",
    "    output = []\n",
    "    for _, span in itertools.groupby(\n",
    "        enumerate(span_list), lambda p: p[1] - p[0]):\n",
    "        span = list(span)\n",
    "        output.append((span[0][1], span[-1][1]))\n",
    "    return output\n",
    "\n",
    "\n",
    "def fix_spans(spans, text, special_characters=SPECIAL_CHARACTERS):\n",
    "    \"\"\"Applies minor edits to trim spans and remove singletons.\"\"\"\n",
    "    cleaned = []\n",
    "    for begin, end in _contiguous_ranges(spans):\n",
    "        while text[begin] in special_characters and begin < end:\n",
    "            begin += 1\n",
    "        while text[end] in special_characters and begin < end:\n",
    "            end -= 1\n",
    "        if end - begin > 1:\n",
    "            cleaned.extend(range(begin, end + 1))\n",
    "    return cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spans: [22, 23, 24, 127, 128, 129, 130, 131, 132, 133, 134, 135]\n",
      "Text : My neighborhood had a gay, straight, tranny, granny, psycho, non-psycho, maybe=psycho, could be psycho\n",
      "march for under noticed imbeciles.....\n",
      "\n",
      "everyone showed up\n"
     ]
    }
   ],
   "source": [
    "index = 100\n",
    "print(\"Spans:\", train.iloc[index].spans)\n",
    "print(\"Text :\", train.iloc[index].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = train.iloc[index].spans\n",
    "text = train.iloc[index].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = fix_spans(spans, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22, 25, 'toxic'), (127, 136, 'toxic')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_to_ents(nlp(text), set(spans), label='toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x:''.join([' '+x[0][x[1][i]] if x[1][i-1] + 1 != x[1][i] else x[0][x[1][i]] \n",
    "                                      for i in range(len(x[1]))])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_words = func([text, spans])\n",
    "nlp_text = nlp(text)\n",
    "cns_ranges = _contiguous_ranges(spans)\n",
    "#ents = spans_to_ents(nlp(text), set(spans), label='toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(22, 25, 'toxic'), (127, 136, 'toxic')],\n",
       " ['gay', 'imbeciles'],\n",
       " [(22, 24), (127, 135)])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents, toxic_words.split(), cns_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_toxicity(word, text, ent_ranges):\n",
    "    print(text.index(word), word, ent_ranges)\n",
    "    index = text.index(word)\n",
    "    for ent_range in ent_ranges:\n",
    "        if index >= ent_range[0] and index <= ent_range[1]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 a [(22, 24), (127, 135)]\n",
      "22 gay [(22, 24), (127, 135)]\n",
      "76 be [(22, 24), (127, 135)]\n",
      "127 imbeciles [(22, 24), (127, 135)]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for word in nlp_text:\n",
    "    if (word.text in toxic_words) and check_toxicity(word.text, text, cns_ranges):\n",
    "        X.append((word.text, word.pos_, 'toxic'))\n",
    "    else:\n",
    "        X.append((word.text, word.pos_, 'normal'))\n",
    "    \n",
    "#return X, spans, toxic_words, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('My', 'DET', 'normal'),\n",
       " ('neighborhood', 'NOUN', 'normal'),\n",
       " ('had', 'AUX', 'normal'),\n",
       " ('a', 'DET', 'normal'),\n",
       " ('gay', 'ADJ', 'toxic'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('straight', 'ADJ', 'normal'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('tranny', 'PROPN', 'normal'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('granny', 'NOUN', 'normal'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('psycho', 'NOUN', 'normal'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('non', 'ADJ', 'normal'),\n",
       " ('-', 'ADJ', 'normal'),\n",
       " ('psycho', 'ADJ', 'normal'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('maybe', 'ADV', 'normal'),\n",
       " ('=', 'ADP', 'normal'),\n",
       " ('psycho', 'NOUN', 'normal'),\n",
       " (',', 'PUNCT', 'normal'),\n",
       " ('could', 'VERB', 'normal'),\n",
       " ('be', 'AUX', 'normal'),\n",
       " ('psycho', 'PROPN', 'normal'),\n",
       " ('\\n', 'SPACE', 'normal'),\n",
       " ('march', 'PROPN', 'normal'),\n",
       " ('for', 'ADP', 'normal'),\n",
       " ('under', 'ADP', 'normal'),\n",
       " ('noticed', 'ADJ', 'normal'),\n",
       " ('imbeciles', 'NOUN', 'toxic'),\n",
       " ('.....', 'PUNCT', 'normal'),\n",
       " ('\\n\\n', 'SPACE', 'normal'),\n",
       " ('everyone', 'PRON', 'normal'),\n",
       " ('showed', 'VERB', 'normal'),\n",
       " ('up', 'ADP', 'normal')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing plugin EntryPoint(name='Windows (alt)', value='keyrings.alt.Windows', group='keyring.backends').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hb/.local/lib/python3.6/site-packages/keyring/backend.py\", line 203, in _load_plugins\n",
      "    init_func = ep.load()\n",
      "  File \"/home/hb/.local/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 105, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/Windows.py\", line 9, in <module>\n",
      "    from . import file_base\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/file_base.py\", line 13, in <module>\n",
      "    from keyring.util.escape import escape as escape_for_ini\n",
      "ModuleNotFoundError: No module named 'keyring.util.escape'\n",
      "Error initializing plugin EntryPoint(name='file', value='keyrings.alt.file', group='keyring.backends').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hb/.local/lib/python3.6/site-packages/keyring/backend.py\", line 203, in _load_plugins\n",
      "    init_func = ep.load()\n",
      "  File \"/home/hb/.local/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 105, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/file.py\", line 11, in <module>\n",
      "    from keyring.util.escape import escape as escape_for_ini\n",
      "ModuleNotFoundError: No module named 'keyring.util.escape'\n",
      "Error initializing plugin EntryPoint(name='pyfs', value='keyrings.alt.pyfs', group='keyring.backends').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hb/.local/lib/python3.6/site-packages/keyring/backend.py\", line 203, in _load_plugins\n",
      "    init_func = ep.load()\n",
      "  File \"/home/hb/.local/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 105, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/pyfs.py\", line 8, in <module>\n",
      "    from keyring.util.escape import escape as escape_for_ini\n",
      "ModuleNotFoundError: No module named 'keyring.util.escape'\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 54 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.16 in /home/hb/.local/lib/python3.6/site-packages (from hmmlearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.10 in /home/hb/.local/lib/python3.6/site-packages (from hmmlearn) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /home/hb/.local/lib/python3.6/site-packages (from hmmlearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/hb/.local/lib/python3.6/site-packages (from scikit-learn>=0.16->hmmlearn) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hb/.local/lib/python3.6/site-packages (from scikit-learn>=0.16->hmmlearn) (2.1.0)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.2.4\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
